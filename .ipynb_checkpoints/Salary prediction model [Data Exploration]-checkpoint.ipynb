{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary prediction model for programmers\n",
    "## Structure of the code\n",
    "1. **Data exploration**\n",
    "2. Fit regression full model (with all available columns)\n",
    "3. Fit regression partial model (after grouping)<br>\n",
    "4. Interesting observations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98855, 129)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "data = pd.read_csv(\"survey_results_public.csv\",low_memory=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redundant columns\n",
    "DROP_COLUMNS = ['CurrencySymbol','Salary', 'SalaryType', 'Respondent', 'Currency']\n",
    "\n",
    "data.drop(DROP_COLUMNS, axis=1, inplace=True)\n",
    "\n",
    "MULTIPLE_CHOICE = [\n",
    "    'DevType','IDE', 'FrameworkWorkedWith',\n",
    "    'CommunicationTools','EducationTypes','SelfTaughtTypes',\n",
    "    'DatabaseWorkedWith','PlatformWorkedWith',\n",
    "    'Methodology','VersionControl',\n",
    "    'ErgonomicDevices','Gender',\n",
    "    'SexualOrientation','RaceEthnicity', \n",
    "    'LanguageWorkedWith'\n",
    "]\n",
    "\n",
    "\n",
    "# These columns are not useful / hard to interpretate.\n",
    "DROP_COLUMNS = [\n",
    "'AssessJob1','AssessJob2','AssessJob3', 'AssessJob4', 'AssessJob5', 'AssessJob6', 'AssessJob7', 'AssessJob8', 'AssessJob9', 'AssessJob10',\n",
    "'AssessBenefits1','AssessBenefits2', 'AssessBenefits3', 'AssessBenefits4', 'AssessBenefits5', 'AssessBenefits6', 'AssessBenefits7',\n",
    "'AssessBenefits8', 'AssessBenefits9', 'AssessBenefits10', 'AssessBenefits11',\n",
    "'JobContactPriorities1', 'JobContactPriorities2', 'JobContactPriorities3', 'JobContactPriorities4', 'JobContactPriorities5',\n",
    "'JobEmailPriorities1', 'JobEmailPriorities2', 'JobEmailPriorities3', 'JobEmailPriorities4','JobEmailPriorities5', 'JobEmailPriorities6',\n",
    "'JobEmailPriorities7',\n",
    "'AdsPriorities1', 'AdsPriorities2', 'AdsPriorities3', 'AdsPriorities4', 'AdsPriorities5', 'AdsPriorities6', 'AdsPriorities7',\n",
    "'AIDangerous','AIInteresting','AIResponsible','AIFuture',\n",
    "'EthicsChoice','EthicsReport','EthicsResponsible','EthicalImplications',\n",
    "'FrameworkDesireNextYear','LanguageDesireNextYear','DatabaseDesireNextYear','PlatformDesireNextYear',\n",
    "'SurveyTooLong','SurveyEasy',\n",
    "'HypotheticalTools1','HypotheticalTools2','HypotheticalTools3','HypotheticalTools4','HypotheticalTools5',\n",
    "'AdsAgreeDisagree1', 'AdsAgreeDisagree2', 'AdsAgreeDisagree3',\n",
    "'StackOverflowRecommend','StackOverflowVisit','StackOverflowHasAccount','StackOverflowParticipate','StackOverflowJobs','StackOverflowDevStory',\n",
    "'StackOverflowJobsRecommend','StackOverflowConsiderMember',\n",
    "'AdsActions','AdBlockerReasons','AgreeDisagree1','AgreeDisagree2','AgreeDisagree3','JobSatisfaction','CareerSatisfaction','HopeFiveYears',\n",
    "'UpdateCV','HackathonReasons','AdBlocker','AdBlockerDisable','AdBlockerReasons','AdsActions'\n",
    "]\n",
    "\n",
    "data.drop(DROP_COLUMNS, axis=1, inplace=True)\n",
    "df=data[data['ConvertedSalary'].notnull()][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33431, 41)\n",
      "(14271, 41)\n"
     ]
    }
   ],
   "source": [
    "#divide by country type\n",
    "developed_country = ['United States','Japan','Turkey','Germany','United Kingdom','France','Italy','South Korea','Spain','Canada','Australia','Netherlands','Belgium','Greece','Czech Republic','Portugal','Sweden','Austria','Switzerland','Israel','Singapore','Denmark','Finland','Norway','Ireland','New Zealand','Slovenia','Estonia','Cyprus','Luxembourg','Iceland']\n",
    "developed_df = df[df['Country'].isin(developed_country)]\n",
    "developing_df = df[~df['Country'].isin(developed_country)]\n",
    "developed_df.drop(['Country'],axis = 1, inplace = True)\n",
    "developing_df.drop(['Country'],axis = 1, inplace = True)\n",
    "print(developed_df.shape)\n",
    "print(developing_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Filled NaNs in 2 OHE columns with 0\n",
      ">> Filled NaNs in 39 non-OHE columns with median values\n",
      ">> Filled NaNs in 2 OHE columns with 0\n",
      ">> Filled NaNs in 38 non-OHE columns with median values\n",
      ">> Dropping the following columns due to high correlations: []\n",
      ">> Dropping the following columns due to high correlations: []\n"
     ]
    }
   ],
   "source": [
    "def NA(df):\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    dummy_columns = [c for c in df.columns if len(df[c].unique()) == 2]\n",
    "    non_dummy = [c for c in df.columns if c not in dummy_columns]\n",
    "    df[dummy_columns] = df[dummy_columns].fillna(0)\n",
    "    df[non_dummy] = df[non_dummy].fillna(df[non_dummy].median())\n",
    "    print(f\">> Filled NaNs in {len(dummy_columns)} OHE columns with 0\")\n",
    "    print(f\">> Filled NaNs in {len(non_dummy)} non-OHE columns with median values\")\n",
    "\n",
    "NA(developed_df)\n",
    "NA(developing_df)\n",
    "\n",
    "def coef(df):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "    # Drop those columns\n",
    "    print(f\">> Dropping the following columns due to high correlations: {to_drop}\")\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    df = df[df['ConvertedSalary'] != 0]\n",
    "\n",
    "coef(developed_df)\n",
    "coef(developing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33431, 41)\n",
      "(14271, 40)\n"
     ]
    }
   ],
   "source": [
    "print(developed_df.shape)\n",
    "print(developing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_df.to_csv(r'/Users/jolinchen/machine_learning/project/developed_df_full.csv')\n",
    "developing_df.to_csv(r'/Users/jolinchen/machine_learning/project/developing_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Multiple entries in DevType. Added 22 one-hot-encoding columns\n",
      ">> Multiple entries in IDE. Added 24 one-hot-encoding columns\n",
      ">> Multiple entries in FrameworkWorkedWith. Added 14 one-hot-encoding columns\n",
      ">> Multiple entries in CommunicationTools. Added 13 one-hot-encoding columns\n",
      ">> Multiple entries in EducationTypes. Added 11 one-hot-encoding columns\n",
      ">> Multiple entries in SelfTaughtTypes. Added 11 one-hot-encoding columns\n",
      ">> Multiple entries in DatabaseWorkedWith. Added 23 one-hot-encoding columns\n",
      ">> Multiple entries in PlatformWorkedWith. Added 28 one-hot-encoding columns\n",
      ">> Multiple entries in Methodology. Added 12 one-hot-encoding columns\n",
      ">> Multiple entries in VersionControl. Added 9 one-hot-encoding columns\n",
      ">> Multiple entries in ErgonomicDevices. Added 6 one-hot-encoding columns\n",
      ">> Multiple entries in Gender. Added 6 one-hot-encoding columns\n",
      ">> Multiple entries in SexualOrientation. Added 6 one-hot-encoding columns\n",
      ">> Multiple entries in RaceEthnicity. Added 9 one-hot-encoding columns\n",
      ">> Multiple entries in LanguageWorkedWith. Added 40 one-hot-encoding columns\n",
      ">> Multiple entries in DevType. Added 22 one-hot-encoding columns\n",
      ">> Multiple entries in IDE. Added 24 one-hot-encoding columns\n",
      ">> Multiple entries in FrameworkWorkedWith. Added 14 one-hot-encoding columns\n",
      ">> Multiple entries in CommunicationTools. Added 13 one-hot-encoding columns\n",
      ">> Multiple entries in EducationTypes. Added 11 one-hot-encoding columns\n",
      ">> Multiple entries in SelfTaughtTypes. Added 11 one-hot-encoding columns\n",
      ">> Multiple entries in DatabaseWorkedWith. Added 23 one-hot-encoding columns\n",
      ">> Multiple entries in PlatformWorkedWith. Added 28 one-hot-encoding columns\n",
      ">> Multiple entries in Methodology. Added 12 one-hot-encoding columns\n",
      ">> Multiple entries in VersionControl. Added 9 one-hot-encoding columns\n",
      ">> Multiple entries in ErgonomicDevices. Added 6 one-hot-encoding columns\n",
      ">> Multiple entries in Gender. Added 6 one-hot-encoding columns\n",
      ">> Multiple entries in SexualOrientation. Added 6 one-hot-encoding columns\n",
      ">> Multiple entries in RaceEthnicity. Added 9 one-hot-encoding columns\n",
      ">> Multiple entries in LanguageWorkedWith. Added 40 one-hot-encoding columns\n",
      "CPU times: user 1min 14s, sys: 9.41 s, total: 1min 23s\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove outliers\n",
    "def remove_outliers(df):\n",
    "    Q1 = df['ConvertedSalary'].quantile(0.25)\n",
    "    Q3 = df['ConvertedSalary'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    drop_outliers = []\n",
    "    for i in df['ConvertedSalary'].index:\n",
    "        if df['ConvertedSalary'][i] < Q1 - 1.5*IQR or df['ConvertedSalary'][i] > Q3 + 1.5*IQR:\n",
    "            drop_outliers.append(i)\n",
    "    df.drop(drop_outliers, inplace = True)\n",
    "\n",
    "remove_outliers(developed_df)\n",
    "remove_outliers(developing_df)\n",
    "\n",
    "\n",
    "\n",
    "# Go through all object columns\n",
    "def MC(df):\n",
    "    for c in MULTIPLE_CHOICE:\n",
    "\n",
    "        # Check if there are multiple entries in this column\n",
    "        temp = df[c].str.split(';', expand=True)\n",
    "\n",
    "        # Get all the possible values in this column\n",
    "        new_columns = pd.unique(temp.values.ravel())\n",
    "        for new_c in new_columns:\n",
    "            if new_c and new_c is not np.nan:\n",
    "\n",
    "                # Create new column for each unique column\n",
    "                idx = df[c].str.contains(new_c, regex=False).fillna(False)\n",
    "                df.loc[idx, f\"{c}_{new_c}\"] = 1\n",
    "\n",
    "        # Info to the user\n",
    "        print(f\">> Multiple entries in {c}. Added {len(new_columns)} one-hot-encoding columns\")\n",
    "\n",
    "        # Drop the original column\n",
    "        df.drop(c, axis=1, inplace=True)\n",
    "\n",
    "MC(developed_df)\n",
    "MC(developing_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in NA and drop high correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Filled NaNs in 206 OHE columns with 0\n",
      ">> Filled NaNs in 24 non-OHE columns with median values\n",
      ">> Filled NaNs in 206 OHE columns with 0\n",
      ">> Filled NaNs in 23 non-OHE columns with median values\n",
      ">> Dropping the following columns due to high correlations: []\n",
      ">> Dropping the following columns due to high correlations: []\n"
     ]
    }
   ],
   "source": [
    "def NA(df):\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    dummy_columns = [c for c in df.columns if len(df[c].unique()) == 2]\n",
    "    non_dummy = [c for c in df.columns if c not in dummy_columns]\n",
    "    df[dummy_columns] = df[dummy_columns].fillna(0)\n",
    "    df[non_dummy] = df[non_dummy].fillna(df[non_dummy].median())\n",
    "    print(f\">> Filled NaNs in {len(dummy_columns)} OHE columns with 0\")\n",
    "    print(f\">> Filled NaNs in {len(non_dummy)} non-OHE columns with median values\")\n",
    "\n",
    "NA(developed_df)\n",
    "NA(developing_df)\n",
    "\n",
    "def coef(df):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "    # Drop those columns\n",
    "    print(f\">> Dropping the following columns due to high correlations: {to_drop}\")\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    df = df[df['ConvertedSalary'] != 0]\n",
    "\n",
    "coef(developed_df)\n",
    "coef(developing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31226, 230)\n",
      "(13324, 229)\n"
     ]
    }
   ],
   "source": [
    "print(developed_df.shape)\n",
    "print(developing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_df.to_csv(r'/Users/jolinchen/machine_learning/project/developed_df_full.csv')\n",
    "developing_df.to_csv(r'/Users/jolinchen/machine_learning/project/developing_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed_df = pd.get_dummies(developed_df)\n",
    "developing_df = pd.get_dummies(developing_df)\n",
    "developed_df.to_csv(r'/Users/jolinchen/machine_learning/project/developed_df.csv')\n",
    "developing_df.to_csv(r'/Users/jolinchen/machine_learning/project/developing_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
